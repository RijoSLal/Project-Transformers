{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01cfd3ef-7001-4fbd-b3d2-4338ff9e710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61c67c5a-1e09-401d-b60e-264314b60647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.layers import Dense,LayerNormalization,Dropout,MultiHeadAttention,GlobalAveragePooling1D,Embedding,Layer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import ops\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "474d9154-91aa-46ee-807a-27847b646fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d9764dd-3081-45a3-8573-db02bba745a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "521b98bc-3baa-461b-9391-26b30cc2fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=500\n",
    "\n",
    "x_train=pad_sequences(x_train,maxlen=max_len)\n",
    "x_test=pad_sequences(x_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a89cb5e-8f69-4df1-a0cd-cee4ce082601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13bab501-1e23-4c8c-a4ac-03fb3156165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding_Position(Layer): \n",
    "    def __init__(self,vocab=20000,emb=32,max_len=500): \n",
    "        super().__init__() \n",
    "        self.token=Embedding(input_dim=vocab,output_dim=32)\n",
    "        self.pos=Embedding(input_dim=max_len,output_dim=32)\n",
    "\n",
    "    def call(self,inputs): \n",
    "        val=tf.shape(inputs)[-1]\n",
    "        possitions=tf.range(start=0,limit=val)\n",
    "        pos=self.pos(possitions) \n",
    "        x=self.token(inputs)\n",
    "        return pos+x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e76e021-a444-425b-9557-04ff663f6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Block(Layer): \n",
    "    def __init__(self,emb=32,ffn=32):\n",
    "        super().__init__()\n",
    "        self.att=MultiHeadAttention(num_heads=2,key_dim=emb)\n",
    "        self.ff_n=keras.Sequential([Dense(ffn,activation=\"relu\"),Dense(emb,activation=\"relu\")])\n",
    "        self.drop1=Dropout(rate=0.1) \n",
    "        self.drop2=Dropout(rate=0.1) \n",
    "        self.norm1=LayerNormalization(epsilon=1e-5)\n",
    "        self.norm2=LayerNormalization(epsilon=1e-5)\n",
    "\n",
    "    def call(self,inputs): \n",
    "        x1=self.att(inputs,inputs)\n",
    "        x2=self.drop1(x1)\n",
    "        x3=self.norm1(x1+x2)\n",
    "        x4=self.ff_n(x3)\n",
    "        x5=self.drop2(x4)\n",
    "        return self.norm2(x4+x5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46c22cf1-5c85-418e-a1ff-21c879e8f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=keras.Input(shape=(500,))\n",
    "\n",
    "embed=Embedding_Position() \n",
    "x=embed(inputs)\n",
    "\n",
    "trans=Transformer_Block()\n",
    "x=trans(x)\n",
    "\n",
    "x=GlobalAveragePooling1D()(x)\n",
    "x=Dense(256,activation=\"relu\")(x)\n",
    "\n",
    "outputs=Dense(2)(x)\n",
    "\n",
    "model=keras.Model(inputs=inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0857935-aa89-4507-b00b-837bacf46a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afde00fc-baea-4e07-880c-705fcf7b970e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 123ms/step - accuracy: 0.5247 - loss: 0.6846\n",
      "Epoch 2/2\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 125ms/step - accuracy: 0.9072 - loss: 0.2401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c9e020fd1c0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=2,batch_size=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa087017-3502-4e4f-9b91-3bc803078879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 47ms/step - accuracy: 0.8587 - loss: 0.3219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3234214782714844, 0.8603600263595581]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4aea3-ae54-496d-974c-3867bf16511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Te\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ad23bda-afb4-4373-a69b-1e01c46f6379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences:\n",
      " [[10  7  6  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  9  4  2  5 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Vocabulary: ['', '[UNK]', 'worst', 'this', 'the', 'movie', 'machine', 'love', 'learning', 'is', 'i', 'ever']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Sample text data\n",
    "texts = [\"I love machine learning\", \"this is the worst movie ever\"]\n",
    "\n",
    "\n",
    "max_tokens = 20000  \n",
    "max_length = 500    \n",
    "vectorizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode='int',         \n",
    "    output_sequence_length=max_length\n",
    ")\n",
    "\n",
    "\n",
    "vectorizer.adapt(texts)\n",
    "\n",
    "\n",
    "sequences = vectorizer(texts)\n",
    "print(\"Sequences:\\n\", sequences.numpy())\n",
    "\n",
    "\n",
    "vocab = vectorizer.get_vocabulary()\n",
    "print(\"Vocabulary:\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "055e09f0-c48a-4ff8-88fb-f97d1ac80cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "val=sequences[0]\n",
    "new=tf.reshape(val,shape=(1,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a507b00f-0b8e-43b4-af76-08db88320c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.5785829, -0.6677219]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a30dab-f884-4d11-be8e-fa6ac8f555cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
